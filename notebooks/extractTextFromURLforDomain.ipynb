{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect==1.0.9\n",
        "!pip install googletrans==3.1.0a0\n",
        "!pip install iso639==0.1.4\n",
        "!pip install yake==0.4.8\n",
        "!pip install lemminflect==0.2.3\n",
        "!python -m spacy download en_core_web_md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBEHIlYZq1zQ",
        "outputId": "b5ba0e6a-dc09-4c03-f5c4-eb66cd8d8a93"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: langdetect==1.0.9 in /usr/local/lib/python3.7/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from langdetect==1.0.9) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: googletrans==3.1.0a0 in /usr/local/lib/python3.7/dist-packages (3.1.0a0)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.7/dist-packages (from googletrans==3.1.0a0) (0.13.3)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.5.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2022.9.24)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.3.0)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2022.11.1)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (3.0.4)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (0.9.1)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.7/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.2.0)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.7/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (0.9.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.7/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.0.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (5.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: iso639==0.1.4 in /usr/local/lib/python3.7/dist-packages (0.1.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: yake==0.4.8 in /usr/local/lib/python3.7/dist-packages (0.4.8)\n",
            "Requirement already satisfied: segtok in /usr/local/lib/python3.7/dist-packages (from yake==0.4.8) (1.5.11)\n",
            "Requirement already satisfied: jellyfish in /usr/local/lib/python3.7/dist-packages (from yake==0.4.8) (0.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from yake==0.4.8) (1.21.6)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from yake==0.4.8) (0.8.10)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from yake==0.4.8) (2.6.3)\n",
            "Requirement already satisfied: click>=6.0 in /usr/local/lib/python3.7/dist-packages (from yake==0.4.8) (7.1.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from segtok->yake==0.4.8) (2022.6.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: lemminflect==0.2.3 in /usr/local/lib/python3.7/dist-packages (0.2.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lemminflect==0.2.3) (1.21.6)\n",
            "2022-11-14 07:49:42.112145: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-md==3.4.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.4.1/en_core_web_md-3.4.1-py3-none-any.whl (42.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 42.8 MB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-md==3.4.1) (3.4.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.0.9)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.6.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.11.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.10.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.0.7)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (57.4.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (21.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.4.5)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (4.1.1)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.4.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (8.1.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.0.10)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (4.64.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.10.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.21.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.10.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (5.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "id": "HQRgppYMaq_t"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from requests.packages.urllib3.exceptions import InsecureRequestWarning \n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from bs4 import BeautifulSoup\n",
        "from bs4.element import Comment\n",
        "\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "\n",
        "# Disable displaying SSL verification warnings\n",
        "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
        "\n",
        "HEADERS = ({'User-Agent':\n",
        "            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36',\n",
        "            'Accept-Language': 'en-US, en;q=0.5'})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tag_visible(element):\n",
        "  # blacklist = ['style', 'label', '[document]', 'embed', 'img', 'object',\n",
        "  #             'noscript', 'header', 'html', 'iframe', 'audio', 'picture',\n",
        "  #             'meta', 'title', 'aside', 'footer', 'svg', 'base', 'figure',\n",
        "  #             'form', 'nav', 'head', 'link', 'button', 'source', 'canvas',\n",
        "  #             'br', 'input', 'script', 'wbr', 'video', 'param', 'hr', 'li', 'ol', 'ul', 'table', 'th', 'tr', 'td', 'a', 'button', 'span']\n",
        "\n",
        "  required = ['title', 'h1', 'h2','h3', 'h4', 'h5', 'h6', 'strong', 'bold', 'p']\n",
        "              \n",
        "  if element.parent.name not in required:\n",
        "      return False\n",
        "  if isinstance(element, Comment):\n",
        "      return False\n",
        "  return True"
      ],
      "metadata": {
        "id": "24rsdvi4a9-L"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getTextFromURL(url):\n",
        "  try:\n",
        "      page = requests.get(url, headers=HEADERS)          #to extract page from website\n",
        "      html_code = page.content                           #to extract html code from page\n",
        "\n",
        "      soup = BeautifulSoup(html_code, 'html.parser')     #Parse html code\n",
        "      text = soup.findAll(text=True)                     #find all text\n",
        "\n",
        "      text_from_html = ''\n",
        "\n",
        "      visible_texts = filter(tag_visible, text)  \n",
        "      text_from_html = \" \".join(t.strip() for t in visible_texts)\n",
        "\n",
        "      text_from_html = text_from_html.strip()\n",
        "\n",
        "      text_from_html = re.sub('\\n', ' ', text_from_html)\n",
        "      res = re.sub(' +', ' ', text_from_html)\n",
        "\n",
        "      return res\n",
        "\n",
        "  except Exception as e:\n",
        "      print(e)"
      ],
      "metadata": {
        "id": "nJsrscffbAS9"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from langdetect import detect\n",
        "from googletrans import Translator\n",
        "\n",
        "\n",
        "def preProcessForTranslation(text):\n",
        "    # removing english words\n",
        "    txt_list = list(text.split(\" \"))\n",
        "    txt = list(filter(lambda ele: re.search(\"[a-zA-Z\\s]+\", ele) is None, txt_list))\n",
        "    text = ' '.join([str(elem) for elem in txt])\n",
        "\n",
        "    return str(text.strip())\n",
        "\n",
        "\n",
        "\n",
        "def detect_and_translate(text, target_lang):\n",
        "    \n",
        "    result_lang = detect(text)\n",
        "    # print(result_lang)\n",
        "    \n",
        "    if result_lang == target_lang:\n",
        "        return text \n",
        "    \n",
        "    else:\n",
        "        translatedText = \"\"\n",
        "        translator= Translator()\n",
        "        text = preProcessForTranslation(text)\n",
        "\n",
        "        txt_list = list(text.split(\" \"))\n",
        "        chunks = [txt_list[x:x+100] for x in range(0, len(txt_list), 100)]    # limit is of 5000 characters \n",
        "        for i in chunks:\n",
        "            text = ' '.join([str(elem) for elem in i])\n",
        "            translation = translator.translate(text, src=result_lang, dest=target_lang)\n",
        "            translatedText = translatedText + ' ' + translation.text\n",
        "        \n",
        "        return translatedText"
      ],
      "metadata": {
        "id": "Tfrie2isqlyr"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yake\n",
        "import string\n",
        "import nltk\n",
        "# nltk.download('stopwords')\n",
        "# nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import spacy\n",
        "import lemminflect\n",
        "from itertools import combinations\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "\n",
        "\n",
        "def pre_process(titles):\n",
        "    \"\"\"\n",
        "    Pre-processes titles by removing stopwords and lemmatizing text.\n",
        "    :param titles: list of strings, contains target titles,.\n",
        "    :return: preprocessed_title_docs, list containing pre-processed titles.\n",
        "    \"\"\"\n",
        "\n",
        "    # Preprocess all the titles\n",
        "    title_docs = [nlp(x) for x in titles]\n",
        "    preprocessed_title_docs = []\n",
        "    lemmatized_tokens = []\n",
        "    for title_doc in title_docs:\n",
        "        for token in title_doc:\n",
        "            if not token.is_stop:\n",
        "                lemmatized_tokens.append(token.lemma_)\n",
        "        preprocessed_title_docs.append(\" \".join(lemmatized_tokens))\n",
        "        del lemmatized_tokens[\n",
        "            :\n",
        "            ]  # empty the lemmatized tokens list as the code moves onto a new title\n",
        "\n",
        "    return preprocessed_title_docs\n",
        "\n",
        "\n",
        "\n",
        "def similarity_filter(titles):\n",
        "    \"\"\"\n",
        "    Recursively check if titles pass a similarity filter.\n",
        "    :param titles: list of strings, contains titles.\n",
        "    If the function finds titles that fail the similarity test, the above param will be the function output.\n",
        "    :return: this method upon itself unless there are no similar titles; in that case the feed that was passed\n",
        "    in is returned.\n",
        "    \"\"\"\n",
        "\n",
        "    # Preprocess titles\n",
        "    preprocessed_title_docs = pre_process(titles)\n",
        "    # print(preprocessed_title_docs)\n",
        "    # Remove similar titles\n",
        "    all_summary_pairs = list(combinations(preprocessed_title_docs, 2))\n",
        "    similar_titles = []\n",
        "    for pair in all_summary_pairs:\n",
        "        title1 = nlp(pair[0])\n",
        "        title2 = nlp(pair[1])\n",
        "        similarity = title1.similarity(title2)\n",
        "        if similarity > 0.8:\n",
        "            similar_titles.append(pair)\n",
        "\n",
        "    titles_to_remove = []\n",
        "    for a_title in similar_titles:\n",
        "        # Get the index of the first title in the pair\n",
        "        index_for_removal = preprocessed_title_docs.index(a_title[1])\n",
        "        titles_to_remove.append(index_for_removal)\n",
        "\n",
        "    # Get indices of similar titles and remove them\n",
        "    similar_title_counts = set(titles_to_remove)\n",
        "    similar_titles = [\n",
        "        x[1] for x in enumerate(titles) if x[0] in similar_title_counts\n",
        "    ]\n",
        "\n",
        "    # Exit the recursion if there are no longer any similar titles\n",
        "    if len(similar_title_counts) == 0:\n",
        "        return titles\n",
        "\n",
        "    # Continue the recursion if there are still titles to remove\n",
        "    else:\n",
        "        # Remove similar titles from the next input\n",
        "        for title in similar_titles:\n",
        "            idx = titles.index(title)\n",
        "            titles.pop(idx)\n",
        "            \n",
        "        return similarity_filter(titles)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def getDomainTopics(text):\n",
        "    \n",
        "    # PREPROCESSING\n",
        "    # 1. Remove punctuation\n",
        "    # 2. Remove digits\n",
        "    # 3. Convert to lowercase\n",
        "    # 4. Remove stop words\n",
        "    # 5. Lemmatization\n",
        "\n",
        "\n",
        "    def remove_punctuation(text):\n",
        "        punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
        "        return punctuationfree\n",
        "\n",
        "    text=remove_punctuation(text)\n",
        "    text = text.lower()\n",
        "    text = ''.join([i for i in text if not i.isdigit()])\n",
        "    text=\" \".join(text.split())\n",
        "\n",
        "\n",
        "    # filtered_list = []\n",
        "    # stop_words = nltk.corpus.stopwords.words('english')\n",
        "    # words = word_tokenize(text)\n",
        "    # for w in words:\n",
        "    #     if w.lower() not in stop_words:\n",
        "    #         filtered_list.append(w)\n",
        "            \n",
        "    # text = \" \".join(filtered_list)\n",
        "\n",
        "\n",
        "    nlp = spacy.load('en_core_web_md')\n",
        "    doc = nlp(text)\n",
        "    lemmatised=[]\n",
        "\n",
        "    for item in doc:\n",
        "        item = item._.lemma()\n",
        "        lemmatised.append(item)\n",
        "\n",
        "    text=\" \".join(lemmatised)\n",
        "\n",
        "\n",
        "    # YAKE\n",
        "    # optimise parameters to get best results\n",
        "    language = \"en\"\n",
        "    max_ngram_size = 2\n",
        "    deduplication_thresold = 0.9\n",
        "    deduplication_algo = 'seqm'\n",
        "    windowSize = 1\n",
        "    numOfKeywords = 10\n",
        "\n",
        "    kw_extractor = yake.KeywordExtractor(lan=language, \n",
        "                                        n=max_ngram_size, \n",
        "                                        dedupLim=deduplication_thresold, \n",
        "                                        dedupFunc=deduplication_algo, \n",
        "                                        windowsSize=windowSize, \n",
        "                                        top=numOfKeywords)\n",
        "                                                \n",
        "\n",
        "    keywords = kw_extractor.extract_keywords(text)\n",
        "\n",
        "    topics = []\n",
        "\n",
        "    for kw, v in keywords:\n",
        "      words = kw.split()\n",
        "      keyw = \" \".join(sorted(set(words), key=words.index))\n",
        "      topics.append(keyw)\n",
        "        #   print(\"Keyphrase: \",keyw, \": score\", 100-v)\n",
        "    filtered_topics = similarity_filter(topics)\n",
        "\n",
        "    domain = keywords[0][0]\n",
        "    topics = filtered_topics\n",
        "\n",
        "    return domain"
      ],
      "metadata": {
        "id": "rrVZc8RkrcSg"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import iso639\n",
        "from langdetect import detect\n",
        "\n",
        "results = {}\n",
        "links = ['https://medium.com/analytics-vidhya/topic-modelling-using-lda-aa11ec9bec13', 'https://timesofindia.indiatimes.com/', 'https://www.bbc.com/korean/features-63100903', 'https://www.amazon.in/Amazon-Brand-Solimo-Single-Recliner/dp/B0862RSLNX/ref=sr_1_7?qid=1664600663&refinements=p_36%3A3444814031&rnid=3444809031&s=kitchen&sr=1-7', 'https://www.aajtak.in/technology/tech-news/story/pm-narendra-modi-launch-5g-in-india-5g-speed-5g-data-jio-airtel-vi-ttec-1547502-2022-10-01', 'https://www.mk.ru/politics/2022/09/30/putin-raskryl-ne-vse-karty-glavnye-syurprizy-kremlya-vperedi.html?from=main_omk', 'https://gujarati.news18.com/news/tech/imc-2022-electricity-theft-will-be-curbed-dp-1258916.html', 'https://www.flipkart.com/google-pixel-6a-charcoal-128-gb/p/itme5ae89135d44e?pid=MOBGFKX5YUXD74Z3&lid=LSTMOBGFKX5YUXD74Z3MXA2OB&marketplace=FLIPKART&store=tyy%2F4io&srno=b_1_1&otracker=clp_bannerads_1_24.bannerAdCard.BANNERADS_A_mobile-phones-store_WPMQ7E9TZNG3&fm=organic&iid=9cf25f5f-2a59-47dd-b846-1091bb3d8f2a.MOBGFKX5YUXD74Z3.SEARCH&ppt=clp&ppn=mobile-phones-store&ssid=ehewriyw8w0000001667719220727', 'https://byjus.com/jee-advanced/#jee-advanced-counselling']\n",
        "\n",
        "for i in links:\n",
        "  rawOriginalText = getTextFromURL(i)\n",
        "\n",
        "  rawText=\"\"\n",
        "  original_lang = iso639.to_name(detect(rawOriginalText))\n",
        "  if original_lang != 'English':\n",
        "      rawText = detect_and_translate(rawOriginalText, target_lang='en')\n",
        "  else:\n",
        "      rawText = rawOriginalText\n",
        "  domain = getDomainTopics(rawText)\n",
        "\n",
        "  results[i] = domain\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyXSIzknuGCY",
        "outputId": "9c27707a-2c0f-4284-b906-9819b80f9c95"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'https://medium.com/analytics-vidhya/topic-modelling-using-lda-aa11ec9bec13': 'topic modelling', 'https://timesofindia.indiatimes.com/': 'bomma blockbuster', 'https://www.bbc.com/korean/features-63100903': 'sea level', 'https://www.amazon.in/Amazon-Brand-Solimo-Single-Recliner/dp/B0862RSLNX/ref=sr_1_7?qid=1664600663&refinements=p_36%3A3444814031&rnid=3444809031&s=kitchen&sr=1-7': 'solimo biela', 'https://www.aajtak.in/technology/tech-news/story/pm-narendra-modi-launch-5g-in-india-5g-speed-5g-data-jio-airtel-vi-ttec-1547502-2022-10-01': 'telecom service', 'https://www.mk.ru/politics/2022/09/30/putin-raskryl-ne-vse-karty-glavnye-syurprizy-kremlya-vperedi.html?from=main_omk': 'russian federation', 'https://gujarati.news18.com/news/tech/imc-2022-electricity-theft-will-be-curbed-dp-1258916.html': 'curb power', 'https://www.flipkart.com/google-pixel-6a-charcoal-128-gb/p/itme5ae89135d44e?pid=MOBGFKX5YUXD74Z3&lid=LSTMOBGFKX5YUXD74Z3MXA2OB&marketplace=FLIPKART&store=tyy%2F4io&srno=b_1_1&otracker=clp_bannerads_1_24.bannerAdCard.BANNERADS_A_mobile-phones-store_WPMQ7E9TZNG3&fm=organic&iid=9cf25f5f-2a59-47dd-b846-1091bb3d8f2a.MOBGFKX5YUXD74Z3.SEARCH&ppt=clp&ppn=mobile-phones-store&ssid=ehewriyw8w0000001667719220727': 'month ago', 'https://byjus.com/jee-advanced/#jee-advanced-counselling': 'jee advanced'}\n"
          ]
        }
      ]
    }
  ]
}