{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Set: \n",
    "https://github.com/mhjabreel/CharCnn_Keras/tree/master/data/ag_news_csv\n",
    "\n",
    "The AG's news topic classification dataset is constructed by choosing the 4 largest classes from the original corpus. Each class contains 30,000 training samples and 1,900 testing samples. The total number of training samples is 120,000 and testing 7,600. \n",
    "\n",
    "The classes are: \n",
    "\n",
    "* World\n",
    "* Sports\n",
    "* Business\n",
    "* Science/Technology\n",
    "\n",
    "#### For more information on how to use Lbl2Vec, visit the [API Guide](https://lbl2vec.readthedocs.io/en/latest/api.html#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lbl2vec import Lbl2Vec\n",
    "import pandas as pd\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec\n",
    "from gensim.parsing.preprocessing import strip_tags\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train data\n",
    "# ag_train = pd.read_csv('data/train.csv',sep=',',header=None, names=['class','title','description'])\n",
    "ag_train = pd.read_csv('data/compiled_data.csv',sep=',',header=None, names=['class','title','description'])\n",
    "\n",
    "# load test data\n",
    "# ag_test = pd.read_csv('data/test.csv',sep=',',header=None, names=['class','title','description'])\n",
    "ag_test = pd.read_csv('data/delme.csv',sep=',',header=None, names=['class','title','description'])\n",
    "\n",
    "# load labels with keywords\n",
    "labels = pd.read_csv('data/labels.csv',sep=',')\n",
    "\n",
    "# split keywords by separator and save them as array\n",
    "labels['keywords'] = labels['keywords'].apply(lambda x: x.split(' '))\n",
    "\n",
    "# convert description keywords to lowercase\n",
    "labels['keywords'] = labels['keywords'].apply(lambda description_keywords: [keyword.lower() for keyword in description_keywords])\n",
    "\n",
    "# get number of keywords for each class\n",
    "labels['number_of_keywords'] = labels['keywords'].apply(lambda row: len(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_index</th>\n",
       "      <th>class_name</th>\n",
       "      <th>keywords</th>\n",
       "      <th>number_of_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>[crypto, binance, ftx, coinbase, blockchain, s...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ecommerce</td>\n",
       "      <td>[mobile, laptop, smart, watch, resolution, pix...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>educational</td>\n",
       "      <td>[machine, learning, deep, neural, networks, ar...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>[film, movie, show, actor, box, office, festiv...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>news</td>\n",
       "      <td>[india, us, modi, biden, pm, asean, summit, g2...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_index     class_name  \\\n",
       "0            1       business   \n",
       "1            2      ecommerce   \n",
       "2            3    educational   \n",
       "3            4  entertainment   \n",
       "4            5           news   \n",
       "\n",
       "                                            keywords  number_of_keywords  \n",
       "0  [crypto, binance, ftx, coinbase, blockchain, s...                  13  \n",
       "1  [mobile, laptop, smart, watch, resolution, pix...                  14  \n",
       "2  [machine, learning, deep, neural, networks, ar...                  14  \n",
       "3  [film, movie, show, actor, box, office, festiv...                  16  \n",
       "4  [india, us, modi, biden, pm, asean, summit, g2...                  15  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc: document text string\n",
    "# returns tokenized document\n",
    "# strip_tags removes meta tags from the text\n",
    "# simple preprocess converts a document into a list of lowercase tokens, ignoring tokens that are too short or too long \n",
    "# simple preprocess also removes numerical values as well as punktuation characters\n",
    "def tokenize(doc):\n",
    "    return simple_preprocess(strip_tags(doc), deacc=True, min_len=2, max_len=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add data set type column\n",
    "ag_train['data_set_type'] = 'train'\n",
    "ag_test['data_set_type'] = 'test'\n",
    "\n",
    "# concat train and test data\n",
    "ag_full_corpus = pd.concat([ag_train,ag_test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and tag documents combined title + description for Lbl2Vec training\n",
    "ag_full_corpus['tagged_docs'] = ag_full_corpus.apply(lambda row: TaggedDocument(tokenize(row['title'] + '. ' + row['description']), [str(row.name)]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add doc_key column\n",
    "ag_full_corpus['doc_key'] = ag_full_corpus.index.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add class_name column\n",
    "ag_full_corpus = ag_full_corpus.merge(labels, left_on='class', right_on='class_index', how='left').drop(['class', 'keywords'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>data_set_type</th>\n",
       "      <th>tagged_docs</th>\n",
       "      <th>doc_key</th>\n",
       "      <th>class_index</th>\n",
       "      <th>class_name</th>\n",
       "      <th>number_of_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Crypto_CEO_warns_his_industry_faces_2008-style...</td>\n",
       "      <td>CNN values your feedback 1. How relevant is th...</td>\n",
       "      <td>train</td>\n",
       "      <td>([style_crisis_, cnn, values, your, feedback, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>At_least_$1_billion_of_client_funds_missing_at...</td>\n",
       "      <td>CNN values your feedback 1. How relevant is th...</td>\n",
       "      <td>train</td>\n",
       "      <td>([at_least_, cnn, values, your, feedback, how,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Crypto_is_making_a_big_comeback</td>\n",
       "      <td>CNN values your feedback 1. How relevant is th...</td>\n",
       "      <td>train</td>\n",
       "      <td>([cnn, values, your, feedback, how, relevant, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elon_Musk_sold_nearly_$4_billion_worth_of_Tesl...</td>\n",
       "      <td>CNN values your feedback 1. How relevant is th...</td>\n",
       "      <td>train</td>\n",
       "      <td>([cnn, values, your, feedback, how, relevant, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Crypto_giant_Binance_drops_bid_to_save_rival,_...</td>\n",
       "      <td>CNN values your feedback 1. How relevant is th...</td>\n",
       "      <td>train</td>\n",
       "      <td>([cnn, values, your, feedback, how, relevant, ...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Crypto_CEO_warns_his_industry_faces_2008-style...   \n",
       "1  At_least_$1_billion_of_client_funds_missing_at...   \n",
       "2                    Crypto_is_making_a_big_comeback   \n",
       "3  Elon_Musk_sold_nearly_$4_billion_worth_of_Tesl...   \n",
       "4  Crypto_giant_Binance_drops_bid_to_save_rival,_...   \n",
       "\n",
       "                                         description data_set_type  \\\n",
       "0  CNN values your feedback 1. How relevant is th...         train   \n",
       "1  CNN values your feedback 1. How relevant is th...         train   \n",
       "2  CNN values your feedback 1. How relevant is th...         train   \n",
       "3  CNN values your feedback 1. How relevant is th...         train   \n",
       "4  CNN values your feedback 1. How relevant is th...         train   \n",
       "\n",
       "                                         tagged_docs doc_key  class_index  \\\n",
       "0  ([style_crisis_, cnn, values, your, feedback, ...       0            1   \n",
       "1  ([at_least_, cnn, values, your, feedback, how,...       1            1   \n",
       "2  ([cnn, values, your, feedback, how, relevant, ...       2            1   \n",
       "3  ([cnn, values, your, feedback, how, relevant, ...       3            1   \n",
       "4  ([cnn, values, your, feedback, how, relevant, ...       4            1   \n",
       "\n",
       "  class_name  number_of_keywords  \n",
       "0   business                  13  \n",
       "1   business                  13  \n",
       "2   business                  13  \n",
       "3   business                  13  \n",
       "4   business                  13  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ag_full_corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Doc2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to get optimal Lbl2Vec results the given Doc2Vec model \n",
    "# should be trained with the parameters “dbow_words=1” and “dm=0”.\n",
    "doc2vec_model = Doc2Vec(documents=ag_full_corpus['tagged_docs'][ag_full_corpus['data_set_type']=='train'], dbow_words=1, dm=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Lbl2Vec\n",
    "\n",
    "Train a new Lbl2Vec model using a pretrained [Doc2Vec](https://radimrehurek.com/gensim/models/doc2vec.html#gensim.models.doc2vec.Doc2Vec) model:\n",
    "* keywords_list : iterable list of lists with descriptive keywords for each topic.\n",
    "* doc2vec_model : pretrained [gensim.models.doc2vec.Doc2Vec](https://radimrehurek.com/gensim/models/doc2vec.html#gensim.models.doc2vec.Doc2Vec) model. Lbl2Vec uses its word and document vectors to compute the label vectors.\n",
    "* label_names : iterable list of custom names for each label. Label names and keywords of the same topic must have the same index.\n",
    "* similarity_threshold : only documents with a higher similarity to the respective description keywords than this treshold are used to calculate the label embedding.\n",
    "* min_num_docs : minimum number of documents that are used to calculate the label embedding. \n",
    "* epochs : number of iterations over the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model with parameters\n",
    "lbl2vec_model = Lbl2Vec(keywords_list=list(labels['keywords']), doc2vec_model=doc2vec_model, label_names=list(labels['class_name']), similarity_threshold=0.30, min_num_docs=10, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-13 20:27:19,387 - Lbl2Vec - INFO - Load document and word embeddings\n",
      "2022-11-13 20:27:19,391 - Lbl2Vec - INFO - Train label embeddings\n",
      "2022-11-13 20:27:19,394 - Lbl2Vec - WARNING - The following keywords from the 'keywords_list' are unknown to the Doc2Vec model and therefore not used to train the model: coinbase blockchain milllion revenue\n",
      "2022-11-13 20:27:19,398 - Lbl2Vec - WARNING - The following keywords from the 'keywords_list' are unknown to the Doc2Vec model and therefore not used to train the model: laptop smart resolution storage connectivity\n",
      "2022-11-13 20:27:19,404 - Lbl2Vec - WARNING - The following keywords from the 'keywords_list' are unknown to the Doc2Vec model and therefore not used to train the model: actress singer concert tour band\n",
      "2022-11-13 20:27:19,407 - Lbl2Vec - WARNING - The following keywords from the 'keywords_list' are unknown to the Doc2Vec model and therefore not used to train the model: g20 poll\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "lbl2vec_model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict topics of documents used to train Doc2Vec\n",
    "\n",
    "Compute similarity scores of learned document vectors from documents that were used to train the Doc2Vec model to each of the learned label vectors. The similarity scores consist of cosine similarities and therefore have a value range of [-1,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-13 20:45:19,300 - Lbl2Vec - INFO - Get document embeddings from model\n",
      "2022-11-13 20:45:19,305 - Lbl2Vec - INFO - Calculate document<->label similarities\n"
     ]
    }
   ],
   "source": [
    "# predict similarity scores\n",
    "model_docs_lbl_similarities = lbl2vec_model.predict_model_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_key</th>\n",
       "      <th>most_similar_label</th>\n",
       "      <th>highest_similarity_score</th>\n",
       "      <th>business</th>\n",
       "      <th>ecommerce</th>\n",
       "      <th>educational</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>news</td>\n",
       "      <td>0.947287</td>\n",
       "      <td>0.947287</td>\n",
       "      <td>0.947287</td>\n",
       "      <td>0.600837</td>\n",
       "      <td>0.947287</td>\n",
       "      <td>0.947287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>news</td>\n",
       "      <td>0.958892</td>\n",
       "      <td>0.958892</td>\n",
       "      <td>0.958892</td>\n",
       "      <td>0.594815</td>\n",
       "      <td>0.958892</td>\n",
       "      <td>0.958892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>news</td>\n",
       "      <td>0.962748</td>\n",
       "      <td>0.962748</td>\n",
       "      <td>0.962748</td>\n",
       "      <td>0.647924</td>\n",
       "      <td>0.962748</td>\n",
       "      <td>0.962748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>news</td>\n",
       "      <td>0.972864</td>\n",
       "      <td>0.972864</td>\n",
       "      <td>0.972864</td>\n",
       "      <td>0.663397</td>\n",
       "      <td>0.972864</td>\n",
       "      <td>0.972864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>0.987820</td>\n",
       "      <td>0.987820</td>\n",
       "      <td>0.987820</td>\n",
       "      <td>0.680078</td>\n",
       "      <td>0.987820</td>\n",
       "      <td>0.987820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc_key most_similar_label  highest_similarity_score  business  ecommerce  \\\n",
       "0       0               news                  0.947287  0.947287   0.947287   \n",
       "1       1               news                  0.958892  0.958892   0.958892   \n",
       "2       2               news                  0.962748  0.962748   0.962748   \n",
       "3       3               news                  0.972864  0.972864   0.972864   \n",
       "4       4               news                  0.987820  0.987820   0.987820   \n",
       "\n",
       "   educational  entertainment      news  \n",
       "0     0.600837       0.947287  0.947287  \n",
       "1     0.594815       0.958892  0.958892  \n",
       "2     0.647924       0.962748  0.962748  \n",
       "3     0.663397       0.972864  0.972864  \n",
       "4     0.680078       0.987820  0.987820  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_docs_lbl_similarities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_key</th>\n",
       "      <th>most_similar_label</th>\n",
       "      <th>highest_similarity_score</th>\n",
       "      <th>business</th>\n",
       "      <th>ecommerce</th>\n",
       "      <th>educational</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>news</td>\n",
       "      <td>0.947287</td>\n",
       "      <td>0.947287</td>\n",
       "      <td>0.947287</td>\n",
       "      <td>0.600837</td>\n",
       "      <td>0.947287</td>\n",
       "      <td>0.947287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>news</td>\n",
       "      <td>0.958892</td>\n",
       "      <td>0.958892</td>\n",
       "      <td>0.958892</td>\n",
       "      <td>0.594815</td>\n",
       "      <td>0.958892</td>\n",
       "      <td>0.958892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>news</td>\n",
       "      <td>0.962748</td>\n",
       "      <td>0.962748</td>\n",
       "      <td>0.962748</td>\n",
       "      <td>0.647924</td>\n",
       "      <td>0.962748</td>\n",
       "      <td>0.962748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>news</td>\n",
       "      <td>0.972864</td>\n",
       "      <td>0.972864</td>\n",
       "      <td>0.972864</td>\n",
       "      <td>0.663397</td>\n",
       "      <td>0.972864</td>\n",
       "      <td>0.972864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "      <td>0.987820</td>\n",
       "      <td>0.987820</td>\n",
       "      <td>0.987820</td>\n",
       "      <td>0.680078</td>\n",
       "      <td>0.987820</td>\n",
       "      <td>0.987820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>news</td>\n",
       "      <td>0.954411</td>\n",
       "      <td>0.954411</td>\n",
       "      <td>0.954411</td>\n",
       "      <td>0.621703</td>\n",
       "      <td>0.954411</td>\n",
       "      <td>0.954411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>news</td>\n",
       "      <td>0.985901</td>\n",
       "      <td>0.985901</td>\n",
       "      <td>0.985901</td>\n",
       "      <td>0.651554</td>\n",
       "      <td>0.985901</td>\n",
       "      <td>0.985901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>news</td>\n",
       "      <td>0.976708</td>\n",
       "      <td>0.976708</td>\n",
       "      <td>0.976708</td>\n",
       "      <td>0.661348</td>\n",
       "      <td>0.976708</td>\n",
       "      <td>0.976708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>news</td>\n",
       "      <td>0.976484</td>\n",
       "      <td>0.976484</td>\n",
       "      <td>0.976484</td>\n",
       "      <td>0.689421</td>\n",
       "      <td>0.976484</td>\n",
       "      <td>0.976484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>news</td>\n",
       "      <td>0.981094</td>\n",
       "      <td>0.981094</td>\n",
       "      <td>0.981094</td>\n",
       "      <td>0.687815</td>\n",
       "      <td>0.981094</td>\n",
       "      <td>0.981094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>educational</td>\n",
       "      <td>0.853823</td>\n",
       "      <td>0.352686</td>\n",
       "      <td>0.352686</td>\n",
       "      <td>0.853823</td>\n",
       "      <td>0.352686</td>\n",
       "      <td>0.352686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>educational</td>\n",
       "      <td>0.878604</td>\n",
       "      <td>0.358771</td>\n",
       "      <td>0.358771</td>\n",
       "      <td>0.878604</td>\n",
       "      <td>0.358771</td>\n",
       "      <td>0.358771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>educational</td>\n",
       "      <td>0.904543</td>\n",
       "      <td>0.424667</td>\n",
       "      <td>0.424667</td>\n",
       "      <td>0.904543</td>\n",
       "      <td>0.424667</td>\n",
       "      <td>0.424667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>educational</td>\n",
       "      <td>0.700593</td>\n",
       "      <td>0.223834</td>\n",
       "      <td>0.223834</td>\n",
       "      <td>0.700593</td>\n",
       "      <td>0.223834</td>\n",
       "      <td>0.223834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>educational</td>\n",
       "      <td>0.918272</td>\n",
       "      <td>0.426141</td>\n",
       "      <td>0.426141</td>\n",
       "      <td>0.918272</td>\n",
       "      <td>0.426141</td>\n",
       "      <td>0.426141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>educational</td>\n",
       "      <td>0.651222</td>\n",
       "      <td>0.200943</td>\n",
       "      <td>0.200943</td>\n",
       "      <td>0.651222</td>\n",
       "      <td>0.200943</td>\n",
       "      <td>0.200943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>educational</td>\n",
       "      <td>0.938482</td>\n",
       "      <td>0.476640</td>\n",
       "      <td>0.476640</td>\n",
       "      <td>0.938482</td>\n",
       "      <td>0.476640</td>\n",
       "      <td>0.476640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>educational</td>\n",
       "      <td>0.844755</td>\n",
       "      <td>0.414362</td>\n",
       "      <td>0.414362</td>\n",
       "      <td>0.844755</td>\n",
       "      <td>0.414362</td>\n",
       "      <td>0.414362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>educational</td>\n",
       "      <td>0.881548</td>\n",
       "      <td>0.348001</td>\n",
       "      <td>0.348001</td>\n",
       "      <td>0.881548</td>\n",
       "      <td>0.348001</td>\n",
       "      <td>0.348001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>educational</td>\n",
       "      <td>0.720463</td>\n",
       "      <td>0.237612</td>\n",
       "      <td>0.237612</td>\n",
       "      <td>0.720463</td>\n",
       "      <td>0.237612</td>\n",
       "      <td>0.237612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>0.971652</td>\n",
       "      <td>0.971652</td>\n",
       "      <td>0.971652</td>\n",
       "      <td>0.859278</td>\n",
       "      <td>0.971652</td>\n",
       "      <td>0.971652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>0.962286</td>\n",
       "      <td>0.962286</td>\n",
       "      <td>0.962286</td>\n",
       "      <td>0.879921</td>\n",
       "      <td>0.962286</td>\n",
       "      <td>0.962286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>0.947752</td>\n",
       "      <td>0.947752</td>\n",
       "      <td>0.947752</td>\n",
       "      <td>0.696543</td>\n",
       "      <td>0.947752</td>\n",
       "      <td>0.947752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>0.973760</td>\n",
       "      <td>0.973760</td>\n",
       "      <td>0.973760</td>\n",
       "      <td>0.784409</td>\n",
       "      <td>0.973760</td>\n",
       "      <td>0.973760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>ecommerce</td>\n",
       "      <td>0.978092</td>\n",
       "      <td>0.978092</td>\n",
       "      <td>0.978092</td>\n",
       "      <td>0.809644</td>\n",
       "      <td>0.978092</td>\n",
       "      <td>0.978092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>news</td>\n",
       "      <td>0.985019</td>\n",
       "      <td>0.985019</td>\n",
       "      <td>0.985019</td>\n",
       "      <td>0.806901</td>\n",
       "      <td>0.985019</td>\n",
       "      <td>0.985019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>ecommerce</td>\n",
       "      <td>0.970091</td>\n",
       "      <td>0.970091</td>\n",
       "      <td>0.970091</td>\n",
       "      <td>0.867433</td>\n",
       "      <td>0.970091</td>\n",
       "      <td>0.970091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>ecommerce</td>\n",
       "      <td>0.959981</td>\n",
       "      <td>0.959981</td>\n",
       "      <td>0.959981</td>\n",
       "      <td>0.696317</td>\n",
       "      <td>0.959981</td>\n",
       "      <td>0.959981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>news</td>\n",
       "      <td>0.978980</td>\n",
       "      <td>0.978980</td>\n",
       "      <td>0.978980</td>\n",
       "      <td>0.706749</td>\n",
       "      <td>0.978980</td>\n",
       "      <td>0.978980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>ecommerce</td>\n",
       "      <td>0.986503</td>\n",
       "      <td>0.986503</td>\n",
       "      <td>0.986503</td>\n",
       "      <td>0.699876</td>\n",
       "      <td>0.986503</td>\n",
       "      <td>0.986503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>0.919046</td>\n",
       "      <td>0.919046</td>\n",
       "      <td>0.919046</td>\n",
       "      <td>0.655017</td>\n",
       "      <td>0.919046</td>\n",
       "      <td>0.919046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>business</td>\n",
       "      <td>0.996636</td>\n",
       "      <td>0.996636</td>\n",
       "      <td>0.996636</td>\n",
       "      <td>0.709062</td>\n",
       "      <td>0.996636</td>\n",
       "      <td>0.996636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>0.971238</td>\n",
       "      <td>0.971238</td>\n",
       "      <td>0.971238</td>\n",
       "      <td>0.732261</td>\n",
       "      <td>0.971238</td>\n",
       "      <td>0.971238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>news</td>\n",
       "      <td>0.989602</td>\n",
       "      <td>0.989602</td>\n",
       "      <td>0.989602</td>\n",
       "      <td>0.786842</td>\n",
       "      <td>0.989602</td>\n",
       "      <td>0.989602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>0.946321</td>\n",
       "      <td>0.946321</td>\n",
       "      <td>0.946321</td>\n",
       "      <td>0.775914</td>\n",
       "      <td>0.946321</td>\n",
       "      <td>0.946321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>0.968100</td>\n",
       "      <td>0.968100</td>\n",
       "      <td>0.968100</td>\n",
       "      <td>0.774586</td>\n",
       "      <td>0.968100</td>\n",
       "      <td>0.968100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>news</td>\n",
       "      <td>0.991256</td>\n",
       "      <td>0.991256</td>\n",
       "      <td>0.991256</td>\n",
       "      <td>0.719305</td>\n",
       "      <td>0.991256</td>\n",
       "      <td>0.991256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>0.964944</td>\n",
       "      <td>0.964944</td>\n",
       "      <td>0.964944</td>\n",
       "      <td>0.750037</td>\n",
       "      <td>0.964944</td>\n",
       "      <td>0.964944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>news</td>\n",
       "      <td>0.989113</td>\n",
       "      <td>0.989113</td>\n",
       "      <td>0.989113</td>\n",
       "      <td>0.726973</td>\n",
       "      <td>0.989113</td>\n",
       "      <td>0.989113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>0.977991</td>\n",
       "      <td>0.977991</td>\n",
       "      <td>0.977991</td>\n",
       "      <td>0.824415</td>\n",
       "      <td>0.977991</td>\n",
       "      <td>0.977991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_key most_similar_label  highest_similarity_score  business  ecommerce  \\\n",
       "0        0               news                  0.947287  0.947287   0.947287   \n",
       "1        1               news                  0.958892  0.958892   0.958892   \n",
       "2        2               news                  0.962748  0.962748   0.962748   \n",
       "3        3               news                  0.972864  0.972864   0.972864   \n",
       "4        4               news                  0.987820  0.987820   0.987820   \n",
       "5        5               news                  0.954411  0.954411   0.954411   \n",
       "6        6               news                  0.985901  0.985901   0.985901   \n",
       "7        7               news                  0.976708  0.976708   0.976708   \n",
       "8        8               news                  0.976484  0.976484   0.976484   \n",
       "9        9               news                  0.981094  0.981094   0.981094   \n",
       "10      10        educational                  0.853823  0.352686   0.352686   \n",
       "11      11        educational                  0.878604  0.358771   0.358771   \n",
       "12      12        educational                  0.904543  0.424667   0.424667   \n",
       "13      13        educational                  0.700593  0.223834   0.223834   \n",
       "14      14        educational                  0.918272  0.426141   0.426141   \n",
       "15      15        educational                  0.651222  0.200943   0.200943   \n",
       "16      16        educational                  0.938482  0.476640   0.476640   \n",
       "17      17        educational                  0.844755  0.414362   0.414362   \n",
       "18      18        educational                  0.881548  0.348001   0.348001   \n",
       "19      19        educational                  0.720463  0.237612   0.237612   \n",
       "20      20      entertainment                  0.971652  0.971652   0.971652   \n",
       "21      21      entertainment                  0.962286  0.962286   0.962286   \n",
       "22      22      entertainment                  0.947752  0.947752   0.947752   \n",
       "23      23      entertainment                  0.973760  0.973760   0.973760   \n",
       "24      24          ecommerce                  0.978092  0.978092   0.978092   \n",
       "25      25               news                  0.985019  0.985019   0.985019   \n",
       "26      26          ecommerce                  0.970091  0.970091   0.970091   \n",
       "27      27          ecommerce                  0.959981  0.959981   0.959981   \n",
       "28      28               news                  0.978980  0.978980   0.978980   \n",
       "29      29          ecommerce                  0.986503  0.986503   0.986503   \n",
       "30      30      entertainment                  0.919046  0.919046   0.919046   \n",
       "31      31           business                  0.996636  0.996636   0.996636   \n",
       "32      32      entertainment                  0.971238  0.971238   0.971238   \n",
       "33      33               news                  0.989602  0.989602   0.989602   \n",
       "34      34      entertainment                  0.946321  0.946321   0.946321   \n",
       "35      35      entertainment                  0.968100  0.968100   0.968100   \n",
       "36      36               news                  0.991256  0.991256   0.991256   \n",
       "37      37      entertainment                  0.964944  0.964944   0.964944   \n",
       "38      38               news                  0.989113  0.989113   0.989113   \n",
       "39      39      entertainment                  0.977991  0.977991   0.977991   \n",
       "\n",
       "    educational  entertainment      news  \n",
       "0      0.600837       0.947287  0.947287  \n",
       "1      0.594815       0.958892  0.958892  \n",
       "2      0.647924       0.962748  0.962748  \n",
       "3      0.663397       0.972864  0.972864  \n",
       "4      0.680078       0.987820  0.987820  \n",
       "5      0.621703       0.954411  0.954411  \n",
       "6      0.651554       0.985901  0.985901  \n",
       "7      0.661348       0.976708  0.976708  \n",
       "8      0.689421       0.976484  0.976484  \n",
       "9      0.687815       0.981094  0.981094  \n",
       "10     0.853823       0.352686  0.352686  \n",
       "11     0.878604       0.358771  0.358771  \n",
       "12     0.904543       0.424667  0.424667  \n",
       "13     0.700593       0.223834  0.223834  \n",
       "14     0.918272       0.426141  0.426141  \n",
       "15     0.651222       0.200943  0.200943  \n",
       "16     0.938482       0.476640  0.476640  \n",
       "17     0.844755       0.414362  0.414362  \n",
       "18     0.881548       0.348001  0.348001  \n",
       "19     0.720463       0.237612  0.237612  \n",
       "20     0.859278       0.971652  0.971652  \n",
       "21     0.879921       0.962286  0.962286  \n",
       "22     0.696543       0.947752  0.947752  \n",
       "23     0.784409       0.973760  0.973760  \n",
       "24     0.809644       0.978092  0.978092  \n",
       "25     0.806901       0.985019  0.985019  \n",
       "26     0.867433       0.970091  0.970091  \n",
       "27     0.696317       0.959981  0.959981  \n",
       "28     0.706749       0.978980  0.978980  \n",
       "29     0.699876       0.986503  0.986503  \n",
       "30     0.655017       0.919046  0.919046  \n",
       "31     0.709062       0.996636  0.996636  \n",
       "32     0.732261       0.971238  0.971238  \n",
       "33     0.786842       0.989602  0.989602  \n",
       "34     0.775914       0.946321  0.946321  \n",
       "35     0.774586       0.968100  0.968100  \n",
       "36     0.719305       0.991256  0.991256  \n",
       "37     0.750037       0.964944  0.964944  \n",
       "38     0.726973       0.989113  0.989113  \n",
       "39     0.824415       0.977991  0.977991  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_docs_lbl_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate prediction of documents used to train Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge DataFrames to compare the predicted and true topic labels\n",
    "evaluation_train = model_docs_lbl_similarities.merge(ag_full_corpus[ag_full_corpus['data_set_type']=='train'], left_on='doc_key', right_on='doc_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.425\n"
     ]
    }
   ],
   "source": [
    "y_true_train = evaluation_train['class_name']\n",
    "y_pred_train = evaluation_train['most_similar_label']\n",
    "print('F1 score:',f1_score(y_true_train, y_pred_train, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict topics of unknown documents\n",
    "\n",
    "Learn document vectors of new documents that were **not** used to train the Doc2Vec model and compute the similarity scores to each of the learned label vectors. The similarity scores consist of cosine similarities and therefore have a value range of [-1,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-13 20:44:56,698 - Lbl2Vec - INFO - Calculate document embeddings\n",
      "2022-11-13 20:44:57,913 - Lbl2Vec - INFO - Calculate document<->label similarities\n"
     ]
    }
   ],
   "source": [
    "# predict similarity scores of new test documents (they were not used during Doc2Vec training)\n",
    "new_docs_lbl_similarities = lbl2vec_model.predict_new_docs(tagged_docs=ag_full_corpus['tagged_docs'][ag_full_corpus['data_set_type']=='test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_key</th>\n",
       "      <th>most_similar_label</th>\n",
       "      <th>highest_similarity_score</th>\n",
       "      <th>business</th>\n",
       "      <th>ecommerce</th>\n",
       "      <th>educational</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>news</td>\n",
       "      <td>0.911007</td>\n",
       "      <td>0.911007</td>\n",
       "      <td>0.911007</td>\n",
       "      <td>0.595638</td>\n",
       "      <td>0.911007</td>\n",
       "      <td>0.911007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>news</td>\n",
       "      <td>0.867709</td>\n",
       "      <td>0.867709</td>\n",
       "      <td>0.867709</td>\n",
       "      <td>0.549646</td>\n",
       "      <td>0.867709</td>\n",
       "      <td>0.867709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>news</td>\n",
       "      <td>0.888887</td>\n",
       "      <td>0.888887</td>\n",
       "      <td>0.888887</td>\n",
       "      <td>0.591218</td>\n",
       "      <td>0.888887</td>\n",
       "      <td>0.888887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43</td>\n",
       "      <td>news</td>\n",
       "      <td>0.881533</td>\n",
       "      <td>0.881533</td>\n",
       "      <td>0.881533</td>\n",
       "      <td>0.568577</td>\n",
       "      <td>0.881533</td>\n",
       "      <td>0.881533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44</td>\n",
       "      <td>news</td>\n",
       "      <td>0.910535</td>\n",
       "      <td>0.910535</td>\n",
       "      <td>0.910535</td>\n",
       "      <td>0.584487</td>\n",
       "      <td>0.910535</td>\n",
       "      <td>0.910535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc_key most_similar_label  highest_similarity_score  business  ecommerce  \\\n",
       "0      40               news                  0.911007  0.911007   0.911007   \n",
       "1      41               news                  0.867709  0.867709   0.867709   \n",
       "2      42               news                  0.888887  0.888887   0.888887   \n",
       "3      43               news                  0.881533  0.881533   0.881533   \n",
       "4      44               news                  0.910535  0.910535   0.910535   \n",
       "\n",
       "   educational  entertainment      news  \n",
       "0     0.595638       0.911007  0.911007  \n",
       "1     0.549646       0.867709  0.867709  \n",
       "2     0.591218       0.888887  0.888887  \n",
       "3     0.568577       0.881533  0.881533  \n",
       "4     0.584487       0.910535  0.910535  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_docs_lbl_similarities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate prediction of new documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge DataFrames to compare the predicted and true topic labels\n",
    "evaluation_test = new_docs_lbl_similarities.merge(ag_full_corpus[ag_full_corpus['data_set_type']=='test'], left_on='doc_key', right_on='doc_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.35\n"
     ]
    }
   ],
   "source": [
    "y_true_test = evaluation_test['class_name']\n",
    "y_pred_test = evaluation_test['most_similar_label']\n",
    "print('F1 score:',f1_score(y_true_test, y_pred_test, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
